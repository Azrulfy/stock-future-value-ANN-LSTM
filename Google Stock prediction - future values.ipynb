{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stock_data(stock_name, normalized=0):\n",
    "    \n",
    "    url=\"http://www.google.com/finance/historical?q=\"+stock_name+\"&startdate=Aug+03%2C+2015&enddate=Aug+02%2C+2017&num=30&ei=d7d4WbrtDYq1swH0mp-4CA&output=csv\" \n",
    "    print(url)\n",
    "    col_names = ['Date','Open','High','Low','Close','Volume']\n",
    "    stock = pd.read_csv(url, header=0, names=col_names) \n",
    "    df = pd.DataFrame(stock)\n",
    "\n",
    "    df[\"Volume\"] = df[\"Volume\"] / 10000\n",
    "    df.drop(df.columns[[0,3,5]], axis=1, inplace=True) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.google.com/finance/historical?q=GOOGL&startdate=Aug+03%2C+2015&enddate=Aug+02%2C+2017&num=30&ei=d7d4WbrtDYq1swH0mp-4CA&output=csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>948.37</td>\n",
       "      <td>949.10</td>\n",
       "      <td>947.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>947.81</td>\n",
       "      <td>954.49</td>\n",
       "      <td>946.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>960.00</td>\n",
       "      <td>961.19</td>\n",
       "      <td>945.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>947.99</td>\n",
       "      <td>961.79</td>\n",
       "      <td>958.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>969.18</td>\n",
       "      <td>969.52</td>\n",
       "      <td>952.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open    High   Close\n",
       "0  948.37  949.10  947.64\n",
       "1  947.81  954.49  946.56\n",
       "2  960.00  961.19  945.50\n",
       "3  947.99  961.79  958.33\n",
       "4  969.18  969.52  952.51"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_name = 'GOOGL'\n",
    "df = get_stock_data(stock_name,0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.94837</td>\n",
       "      <td>0.94910</td>\n",
       "      <td>0.94764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.94781</td>\n",
       "      <td>0.95449</td>\n",
       "      <td>0.94656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.96000</td>\n",
       "      <td>0.96119</td>\n",
       "      <td>0.94550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.94799</td>\n",
       "      <td>0.96179</td>\n",
       "      <td>0.95833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.96918</td>\n",
       "      <td>0.96952</td>\n",
       "      <td>0.95251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.97278</td>\n",
       "      <td>0.97395</td>\n",
       "      <td>0.96531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.97070</td>\n",
       "      <td>0.97673</td>\n",
       "      <td>0.96903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.99410</td>\n",
       "      <td>1.00619</td>\n",
       "      <td>0.99831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.98900</td>\n",
       "      <td>0.99511</td>\n",
       "      <td>0.99384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.99700</td>\n",
       "      <td>0.99868</td>\n",
       "      <td>0.99219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.99001</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>0.99277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.97336</td>\n",
       "      <td>0.99085</td>\n",
       "      <td>0.98695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.97632</td>\n",
       "      <td>0.98335</td>\n",
       "      <td>0.97596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.97400</td>\n",
       "      <td>0.97754</td>\n",
       "      <td>0.97691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.97080</td>\n",
       "      <td>0.97870</td>\n",
       "      <td>0.96885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.96086</td>\n",
       "      <td>0.96963</td>\n",
       "      <td>0.96766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.95052</td>\n",
       "      <td>0.95489</td>\n",
       "      <td>0.95353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.94195</td>\n",
       "      <td>0.95313</td>\n",
       "      <td>0.95100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.93098</td>\n",
       "      <td>0.94466</td>\n",
       "      <td>0.94081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.92500</td>\n",
       "      <td>0.93614</td>\n",
       "      <td>0.92769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open     High    Close\n",
       "0   0.94837  0.94910  0.94764\n",
       "1   0.94781  0.95449  0.94656\n",
       "2   0.96000  0.96119  0.94550\n",
       "3   0.94799  0.96179  0.95833\n",
       "4   0.96918  0.96952  0.95251\n",
       "5   0.97278  0.97395  0.96531\n",
       "6   0.97070  0.97673  0.96903\n",
       "7   0.99410  1.00619  0.99831\n",
       "8   0.98900  0.99511  0.99384\n",
       "9   0.99700  0.99868  0.99219\n",
       "10  0.99001  0.99560  0.99277\n",
       "11  0.97336  0.99085  0.98695\n",
       "12  0.97632  0.98335  0.97596\n",
       "13  0.97400  0.97754  0.97691\n",
       "14  0.97080  0.97870  0.96885\n",
       "15  0.96086  0.96963  0.96766\n",
       "16  0.95052  0.95489  0.95353\n",
       "17  0.94195  0.95313  0.95100\n",
       "18  0.93098  0.94466  0.94081\n",
       "19  0.92500  0.93614  0.92769"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization\n",
    "\n",
    "df['High'] = df['High'] / 1000\n",
    "df['Open'] = df['Open'] / 1000\n",
    "df['Close'] = df['Close'] / 1000\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(df, seq_len):\n",
    "    amount_of_features = len(df.columns)\n",
    "    data = df.as_matrix()\n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "\n",
    "    result = np.array(result)\n",
    "    row = 1.0 * result.shape[0]\n",
    "    train = result[:int(row), :]\n",
    "    x_train = train[:-3, :-1]\n",
    "    y_train = train[3:, -1][:,-1]\n",
    "    x_test = result[int(row):-3, :-1]\n",
    "    y_test = result[int(row)+3:, -1][:,-1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (491, 10, 3)\n",
      "y_train (491,)\n",
      "X_test (0, 10, 3)\n",
      "y_test (0,)\n",
      "[[ 0.68404  0.69226  0.68937]\n",
      " [ 0.68804  0.69474  0.69411]\n",
      " [ 0.69107  0.69576  0.68873]\n",
      " [ 0.69011  0.7002   0.69404]\n",
      " [ 0.6891   0.69616  0.67948]\n",
      " [ 0.67104  0.67289  0.64403]\n",
      " [ 0.6006   0.64433  0.61811]\n",
      " [ 0.64647  0.647    0.61247]\n",
      " [ 0.6431   0.66248  0.65974]\n",
      " [ 0.67199  0.67398  0.66796]]\n",
      "[ 0.67948  0.64403  0.61811  0.61247  0.65974  0.66796  0.65969  0.64782\n",
      "  0.62956  0.64491]\n"
     ]
    }
   ],
   "source": [
    "window = 10\n",
    "X_train, y_train, X_test, y_test = load_data(df[::-1], window)\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)\n",
    "print(X_train[:-1][:,-1][:10])\n",
    "print(y_train[:-1][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model2(layers):\n",
    "    d = 0.2\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(d))\n",
    "    \n",
    "    model.add(LSTM(128, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(d))\n",
    "    \n",
    "    model.add(Dense(32,init='uniform',activation='relu'))        \n",
    "    model.add(Dense(1,init='uniform',activation='relu'))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "amount_of_features = len(df.columns)\n",
    "# model = build_model([amount_of_features,lag,1])\n",
    "model = build_model2([amount_of_features,window,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "491/491 [==============================] - 3s - loss: 0.6198 - acc: 0.0000e+00     \n",
      "Epoch 2/200\n",
      "491/491 [==============================] - 1s - loss: 0.5564 - acc: 0.0000e+00     \n",
      "Epoch 3/200\n",
      "491/491 [==============================] - 1s - loss: 0.5047 - acc: 0.0000e+00     \n",
      "Epoch 4/200\n",
      "491/491 [==============================] - 1s - loss: 0.4527 - acc: 0.0000e+00     \n",
      "Epoch 5/200\n",
      "491/491 [==============================] - 1s - loss: 0.4002 - acc: 0.0000e+00     \n",
      "Epoch 6/200\n",
      "491/491 [==============================] - 1s - loss: 0.3512 - acc: 0.0000e+00     \n",
      "Epoch 7/200\n",
      "491/491 [==============================] - 1s - loss: 0.2993 - acc: 0.0000e+00     \n",
      "Epoch 8/200\n",
      "491/491 [==============================] - 1s - loss: 0.2554 - acc: 0.0000e+00     \n",
      "Epoch 9/200\n",
      "491/491 [==============================] - 1s - loss: 0.2199 - acc: 0.0000e+00     \n",
      "Epoch 10/200\n",
      "491/491 [==============================] - 1s - loss: 0.1853 - acc: 0.0000e+00     \n",
      "Epoch 11/200\n",
      "491/491 [==============================] - 1s - loss: 0.1581 - acc: 0.0000e+00     \n",
      "Epoch 12/200\n",
      "491/491 [==============================] - 1s - loss: 0.1189 - acc: 0.0000e+00     \n",
      "Epoch 13/200\n",
      "491/491 [==============================] - 1s - loss: 0.0892 - acc: 0.0000e+00     \n",
      "Epoch 14/200\n",
      "491/491 [==============================] - 1s - loss: 0.0573 - acc: 0.0000e+00     \n",
      "Epoch 15/200\n",
      "491/491 [==============================] - 1s - loss: 0.0405 - acc: 0.0000e+00     \n",
      "Epoch 16/200\n",
      "491/491 [==============================] - 1s - loss: 0.0328 - acc: 0.0000e+00     \n",
      "Epoch 17/200\n",
      "491/491 [==============================] - 1s - loss: 0.0182 - acc: 0.0000e+00     \n",
      "Epoch 18/200\n",
      "491/491 [==============================] - 1s - loss: 0.0104 - acc: 0.0000e+00     \n",
      "Epoch 19/200\n",
      "491/491 [==============================] - 1s - loss: 0.0115 - acc: 0.0000e+00     \n",
      "Epoch 20/200\n",
      "491/491 [==============================] - 1s - loss: 0.0132 - acc: 0.0000e+00     \n",
      "Epoch 21/200\n",
      "491/491 [==============================] - 1s - loss: 0.0155 - acc: 0.0000e+00     \n",
      "Epoch 22/200\n",
      "491/491 [==============================] - 1s - loss: 0.0117 - acc: 0.0000e+00     \n",
      "Epoch 23/200\n",
      "491/491 [==============================] - 1s - loss: 0.0122 - acc: 0.0000e+00     \n",
      "Epoch 24/200\n",
      "491/491 [==============================] - 1s - loss: 0.0079 - acc: 0.0000e+00     \n",
      "Epoch 25/200\n",
      "491/491 [==============================] - 1s - loss: 0.0085 - acc: 0.0000e+00     \n",
      "Epoch 26/200\n",
      "491/491 [==============================] - 1s - loss: 0.0116 - acc: 0.0000e+00     \n",
      "Epoch 27/200\n",
      "491/491 [==============================] - 1s - loss: 0.0061 - acc: 0.0000e+00     \n",
      "Epoch 28/200\n",
      "491/491 [==============================] - 1s - loss: 0.0060 - acc: 0.0000e+00     \n",
      "Epoch 29/200\n",
      "491/491 [==============================] - 1s - loss: 0.0129 - acc: 0.0000e+00     \n",
      "Epoch 30/200\n",
      "491/491 [==============================] - 1s - loss: 0.0132 - acc: 0.0000e+00     \n",
      "Epoch 31/200\n",
      "491/491 [==============================] - 1s - loss: 0.0079 - acc: 0.0000e+00     \n",
      "Epoch 32/200\n",
      "491/491 [==============================] - 1s - loss: 0.0121 - acc: 0.0000e+00     \n",
      "Epoch 33/200\n",
      "491/491 [==============================] - 1s - loss: 0.0044 - acc: 0.0000e+00     \n",
      "Epoch 34/200\n",
      "491/491 [==============================] - 1s - loss: 0.0113 - acc: 0.0000e+00     \n",
      "Epoch 35/200\n",
      "491/491 [==============================] - 1s - loss: 0.0056 - acc: 0.0000e+00     \n",
      "Epoch 36/200\n",
      "491/491 [==============================] - 1s - loss: 0.0069 - acc: 0.0000e+00     \n",
      "Epoch 37/200\n",
      "491/491 [==============================] - 1s - loss: 0.0046 - acc: 0.0000e+00     \n",
      "Epoch 38/200\n",
      "491/491 [==============================] - 1s - loss: 0.0046 - acc: 0.0000e+00     \n",
      "Epoch 39/200\n",
      "491/491 [==============================] - 1s - loss: 0.0037 - acc: 0.0000e+00     \n",
      "Epoch 40/200\n",
      "491/491 [==============================] - 1s - loss: 0.0034 - acc: 0.0000e+00     \n",
      "Epoch 41/200\n",
      "491/491 [==============================] - 1s - loss: 0.0037 - acc: 0.0000e+00     \n",
      "Epoch 42/200\n",
      "491/491 [==============================] - 1s - loss: 0.0031 - acc: 0.0000e+00     \n",
      "Epoch 43/200\n",
      "491/491 [==============================] - 1s - loss: 0.0031 - acc: 0.0000e+00     \n",
      "Epoch 44/200\n",
      "491/491 [==============================] - 1s - loss: 0.0099 - acc: 0.0000e+00     \n",
      "Epoch 45/200\n",
      "491/491 [==============================] - 1s - loss: 0.0072 - acc: 0.0000e+00     \n",
      "Epoch 46/200\n",
      "491/491 [==============================] - 1s - loss: 0.0047 - acc: 0.0000e+00     \n",
      "Epoch 47/200\n",
      "491/491 [==============================] - 1s - loss: 0.0083 - acc: 0.0000e+00     \n",
      "Epoch 48/200\n",
      "491/491 [==============================] - 1s - loss: 0.0068 - acc: 0.0000e+00     \n",
      "Epoch 49/200\n",
      "491/491 [==============================] - 1s - loss: 0.0070 - acc: 0.0000e+00     \n",
      "Epoch 50/200\n",
      "491/491 [==============================] - 1s - loss: 0.0067 - acc: 0.0000e+00     \n",
      "Epoch 51/200\n",
      "491/491 [==============================] - 1s - loss: 0.0068 - acc: 0.0000e+00     \n",
      "Epoch 52/200\n",
      "491/491 [==============================] - 1s - loss: 0.0041 - acc: 0.0000e+00     \n",
      "Epoch 53/200\n",
      "491/491 [==============================] - 1s - loss: 0.0074 - acc: 0.0000e+00     \n",
      "Epoch 54/200\n",
      "491/491 [==============================] - 1s - loss: 0.0064 - acc: 0.0000e+00     \n",
      "Epoch 55/200\n",
      "491/491 [==============================] - 1s - loss: 0.0044 - acc: 0.0000e+00     \n",
      "Epoch 56/200\n",
      "491/491 [==============================] - 1s - loss: 0.0040 - acc: 0.0000e+00     \n",
      "Epoch 57/200\n",
      "491/491 [==============================] - 1s - loss: 0.0040 - acc: 0.0000e+00     \n",
      "Epoch 58/200\n",
      "491/491 [==============================] - 1s - loss: 0.0050 - acc: 0.0000e+00     \n",
      "Epoch 59/200\n",
      "491/491 [==============================] - 1s - loss: 0.0033 - acc: 0.0000e+00     \n",
      "Epoch 60/200\n",
      "491/491 [==============================] - 1s - loss: 0.0058 - acc: 0.0000e+00     \n",
      "Epoch 61/200\n",
      "491/491 [==============================] - 1s - loss: 0.0149 - acc: 0.0000e+00     \n",
      "Epoch 62/200\n",
      "491/491 [==============================] - 1s - loss: 0.0027 - acc: 0.0000e+00     \n",
      "Epoch 63/200\n",
      "491/491 [==============================] - 1s - loss: 0.0049 - acc: 0.0000e+00     \n",
      "Epoch 64/200\n",
      "491/491 [==============================] - 1s - loss: 0.0039 - acc: 0.0000e+00     \n",
      "Epoch 65/200\n",
      "491/491 [==============================] - 1s - loss: 0.0071 - acc: 0.0000e+00     \n",
      "Epoch 66/200\n",
      "491/491 [==============================] - 1s - loss: 0.0039 - acc: 0.0000e+00     \n",
      "Epoch 67/200\n",
      "491/491 [==============================] - 1s - loss: 0.0033 - acc: 0.0000e+00     \n",
      "Epoch 68/200\n",
      "491/491 [==============================] - 1s - loss: 0.0075 - acc: 0.0000e+00     \n",
      "Epoch 69/200\n",
      "491/491 [==============================] - 1s - loss: 0.0057 - acc: 0.0000e+00     \n",
      "Epoch 70/200\n",
      "491/491 [==============================] - 1s - loss: 0.0041 - acc: 0.0000e+00     \n",
      "Epoch 71/200\n",
      "491/491 [==============================] - 1s - loss: 0.0041 - acc: 0.0000e+00     \n",
      "Epoch 72/200\n",
      "491/491 [==============================] - 1s - loss: 0.0052 - acc: 0.0000e+00     \n",
      "Epoch 73/200\n",
      "491/491 [==============================] - 1s - loss: 0.0061 - acc: 0.0000e+00     \n",
      "Epoch 74/200\n",
      "491/491 [==============================] - 1s - loss: 0.0031 - acc: 0.0000e+00     \n",
      "Epoch 75/200\n",
      "491/491 [==============================] - 1s - loss: 0.0070 - acc: 0.0000e+00     \n",
      "Epoch 76/200\n",
      "491/491 [==============================] - 1s - loss: 0.0053 - acc: 0.0000e+00     \n",
      "Epoch 77/200\n",
      "491/491 [==============================] - 1s - loss: 0.0028 - acc: 0.0000e+00     \n",
      "Epoch 78/200\n",
      "491/491 [==============================] - 1s - loss: 0.0034 - acc: 0.0000e+00     \n",
      "Epoch 79/200\n",
      "491/491 [==============================] - 1s - loss: 0.0048 - acc: 0.0000e+00     \n",
      "Epoch 80/200\n",
      "491/491 [==============================] - 1s - loss: 0.0025 - acc: 0.0000e+00     \n",
      "Epoch 81/200\n",
      "491/491 [==============================] - 1s - loss: 0.0045 - acc: 0.0000e+00     \n",
      "Epoch 82/200\n",
      "491/491 [==============================] - 1s - loss: 0.0029 - acc: 0.0000e+00     \n",
      "Epoch 83/200\n",
      "491/491 [==============================] - 1s - loss: 0.0144 - acc: 0.0000e+00     \n",
      "Epoch 84/200\n",
      "491/491 [==============================] - 1s - loss: 0.0113 - acc: 0.0000e+00     \n",
      "Epoch 85/200\n",
      "491/491 [==============================] - 1s - loss: 0.0029 - acc: 0.0000e+00     \n",
      "Epoch 86/200\n",
      "491/491 [==============================] - 1s - loss: 0.0129 - acc: 0.0000e+00     \n",
      "Epoch 87/200\n",
      "491/491 [==============================] - 1s - loss: 0.0060 - acc: 0.0000e+00     \n",
      "Epoch 88/200\n",
      "491/491 [==============================] - 1s - loss: 0.0043 - acc: 0.0000e+00     \n",
      "Epoch 89/200\n",
      "491/491 [==============================] - 1s - loss: 0.0054 - acc: 0.0000e+00     \n",
      "Epoch 90/200\n",
      "491/491 [==============================] - 1s - loss: 0.0035 - acc: 0.0000e+00     \n",
      "Epoch 91/200\n",
      "491/491 [==============================] - 1s - loss: 0.0053 - acc: 0.0000e+00     \n",
      "Epoch 92/200\n",
      "491/491 [==============================] - 1s - loss: 0.0054 - acc: 0.0000e+00     \n",
      "Epoch 93/200\n",
      "491/491 [==============================] - 1s - loss: 0.0032 - acc: 0.0000e+00     \n",
      "Epoch 94/200\n",
      "491/491 [==============================] - 1s - loss: 0.0032 - acc: 0.0000e+00     \n",
      "Epoch 95/200\n",
      "491/491 [==============================] - 1s - loss: 0.0038 - acc: 0.0000e+00     \n",
      "Epoch 96/200\n",
      "491/491 [==============================] - 1s - loss: 0.0031 - acc: 0.0000e+00     \n",
      "Epoch 97/200\n",
      "491/491 [==============================] - 1s - loss: 0.0036 - acc: 0.0000e+00     \n",
      "Epoch 98/200\n",
      "491/491 [==============================] - 1s - loss: 0.0033 - acc: 0.0000e+00     \n",
      "Epoch 99/200\n",
      "491/491 [==============================] - 1s - loss: 0.0166 - acc: 0.0000e+00     \n",
      "Epoch 100/200\n",
      "491/491 [==============================] - 1s - loss: 0.0030 - acc: 0.0000e+00     \n",
      "Epoch 101/200\n",
      "491/491 [==============================] - 1s - loss: 0.0039 - acc: 0.0000e+00     \n",
      "Epoch 102/200\n",
      "491/491 [==============================] - 1s - loss: 0.0037 - acc: 0.0000e+00     \n",
      "Epoch 103/200\n",
      "491/491 [==============================] - 1s - loss: 0.0036 - acc: 0.0000e+00     \n",
      "Epoch 104/200\n",
      "491/491 [==============================] - 1s - loss: 0.0032 - acc: 0.0000e+00     \n",
      "Epoch 105/200\n",
      "491/491 [==============================] - 1s - loss: 0.0033 - acc: 0.0000e+00     \n",
      "Epoch 106/200\n",
      "491/491 [==============================] - 1s - loss: 0.0041 - acc: 0.0000e+00     \n",
      "Epoch 107/200\n",
      "491/491 [==============================] - 1s - loss: 0.0034 - acc: 0.0000e+00     \n",
      "Epoch 108/200\n",
      "491/491 [==============================] - 1s - loss: 0.0035 - acc: 0.0000e+00     \n",
      "Epoch 109/200\n",
      "491/491 [==============================] - 1s - loss: 0.0044 - acc: 0.0000e+00     \n",
      "Epoch 110/200\n",
      "491/491 [==============================] - 1s - loss: 0.0024 - acc: 0.0000e+00     \n",
      "Epoch 111/200\n",
      "491/491 [==============================] - 1s - loss: 0.0026 - acc: 0.0000e+00     \n",
      "Epoch 112/200\n",
      "491/491 [==============================] - 1s - loss: 0.0027 - acc: 0.0000e+00     \n",
      "Epoch 113/200\n",
      "491/491 [==============================] - 1s - loss: 0.0061 - acc: 0.0000e+00     \n",
      "Epoch 114/200\n",
      "491/491 [==============================] - 1s - loss: 0.0038 - acc: 0.0000e+00     \n",
      "Epoch 115/200\n",
      "491/491 [==============================] - 1s - loss: 0.0029 - acc: 0.0000e+00     \n",
      "Epoch 116/200\n",
      "491/491 [==============================] - 1s - loss: 0.0032 - acc: 0.0000e+00     \n",
      "Epoch 117/200\n",
      "491/491 [==============================] - 1s - loss: 0.0026 - acc: 0.0000e+00     \n",
      "Epoch 118/200\n",
      "491/491 [==============================] - 1s - loss: 0.0199 - acc: 0.0000e+00     \n",
      "Epoch 119/200\n",
      "491/491 [==============================] - 1s - loss: 0.0047 - acc: 0.0000e+00     \n",
      "Epoch 120/200\n",
      "491/491 [==============================] - 1s - loss: 0.0029 - acc: 0.0000e+00     \n",
      "Epoch 121/200\n",
      "491/491 [==============================] - 1s - loss: 0.0039 - acc: 0.0000e+00     \n",
      "Epoch 122/200\n",
      "491/491 [==============================] - 1s - loss: 0.0047 - acc: 0.0000e+00     \n",
      "Epoch 123/200\n",
      "491/491 [==============================] - 1s - loss: 0.0069 - acc: 0.0000e+00     \n",
      "Epoch 124/200\n",
      "491/491 [==============================] - 1s - loss: 0.0035 - acc: 0.0000e+00     \n",
      "Epoch 125/200\n",
      "491/491 [==============================] - 1s - loss: 0.0047 - acc: 0.0000e+00     \n",
      "Epoch 126/200\n",
      "491/491 [==============================] - 1s - loss: 0.0047 - acc: 0.0000e+00     \n",
      "Epoch 127/200\n",
      "491/491 [==============================] - 1s - loss: 0.0029 - acc: 0.0000e+00     \n",
      "Epoch 128/200\n",
      "491/491 [==============================] - 1s - loss: 0.0028 - acc: 0.0000e+00     \n",
      "Epoch 129/200\n",
      "491/491 [==============================] - 1s - loss: 0.0032 - acc: 0.0000e+00     \n",
      "Epoch 130/200\n",
      "491/491 [==============================] - 1s - loss: 0.0040 - acc: 0.0000e+00     \n",
      "Epoch 131/200\n",
      "491/491 [==============================] - 1s - loss: 0.0028 - acc: 0.0000e+00     \n",
      "Epoch 132/200\n",
      "491/491 [==============================] - 1s - loss: 0.0065 - acc: 0.0000e+00     \n",
      "Epoch 133/200\n",
      "491/491 [==============================] - 1s - loss: 0.0045 - acc: 0.0000e+00     \n",
      "Epoch 134/200\n",
      "491/491 [==============================] - 1s - loss: 0.0030 - acc: 0.0000e+00     \n",
      "Epoch 135/200\n",
      "491/491 [==============================] - 1s - loss: 0.0024 - acc: 0.0000e+00     \n",
      "Epoch 136/200\n",
      "491/491 [==============================] - 1s - loss: 0.0040 - acc: 0.0000e+00     \n",
      "Epoch 137/200\n",
      "491/491 [==============================] - 1s - loss: 0.0026 - acc: 0.0000e+00     \n",
      "Epoch 138/200\n",
      "491/491 [==============================] - 1s - loss: 0.0073 - acc: 0.0000e+00     \n",
      "Epoch 139/200\n",
      "491/491 [==============================] - 1s - loss: 0.0042 - acc: 0.0000e+00     \n",
      "Epoch 140/200\n",
      "491/491 [==============================] - 1s - loss: 0.0035 - acc: 0.0000e+00     \n",
      "Epoch 141/200\n",
      "491/491 [==============================] - 1s - loss: 0.0043 - acc: 0.0000e+00     \n",
      "Epoch 142/200\n",
      "491/491 [==============================] - 1s - loss: 0.0031 - acc: 0.0000e+00     \n",
      "Epoch 143/200\n",
      "491/491 [==============================] - 1s - loss: 0.0039 - acc: 0.0000e+00     \n",
      "Epoch 144/200\n",
      "491/491 [==============================] - 1s - loss: 0.0034 - acc: 0.0000e+00     \n",
      "Epoch 145/200\n",
      "491/491 [==============================] - 1s - loss: 0.0068 - acc: 0.0000e+00     \n",
      "Epoch 146/200\n",
      "491/491 [==============================] - 1s - loss: 0.0030 - acc: 0.0000e+00     \n",
      "Epoch 147/200\n",
      "491/491 [==============================] - 1s - loss: 0.0037 - acc: 0.0000e+00     \n",
      "Epoch 148/200\n",
      "491/491 [==============================] - 1s - loss: 0.0033 - acc: 0.0000e+00     \n",
      "Epoch 149/200\n",
      "491/491 [==============================] - 1s - loss: 0.0027 - acc: 0.0000e+00     \n",
      "Epoch 150/200\n",
      "491/491 [==============================] - 1s - loss: 0.0035 - acc: 0.0000e+00     \n",
      "Epoch 151/200\n",
      "491/491 [==============================] - 1s - loss: 0.0027 - acc: 0.0000e+00     \n",
      "Epoch 152/200\n",
      "491/491 [==============================] - 1s - loss: 0.0029 - acc: 0.0000e+00     \n",
      "Epoch 153/200\n",
      "491/491 [==============================] - 1s - loss: 0.0028 - acc: 0.0000e+00     \n",
      "Epoch 154/200\n",
      "491/491 [==============================] - 1s - loss: 0.0028 - acc: 0.0000e+00     \n",
      "Epoch 155/200\n",
      "491/491 [==============================] - 1s - loss: 0.0116 - acc: 0.0000e+00     \n",
      "Epoch 156/200\n",
      "491/491 [==============================] - 1s - loss: 0.0061 - acc: 0.0000e+00     \n",
      "Epoch 157/200\n",
      "491/491 [==============================] - 1s - loss: 0.0036 - acc: 0.0000e+00     \n",
      "Epoch 158/200\n",
      "491/491 [==============================] - 1s - loss: 0.0037 - acc: 0.0000e+00     \n",
      "Epoch 159/200\n",
      "491/491 [==============================] - 1s - loss: 0.0030 - acc: 0.0000e+00     \n",
      "Epoch 160/200\n",
      "491/491 [==============================] - 1s - loss: 0.0029 - acc: 0.0000e+00     \n",
      "Epoch 161/200\n",
      "491/491 [==============================] - 1s - loss: 0.0031 - acc: 0.0000e+00     \n",
      "Epoch 162/200\n",
      "491/491 [==============================] - 1s - loss: 0.0031 - acc: 0.0000e+00     \n",
      "Epoch 163/200\n",
      "491/491 [==============================] - 1s - loss: 0.0040 - acc: 0.0000e+00     \n",
      "Epoch 164/200\n",
      "491/491 [==============================] - 1s - loss: 0.0036 - acc: 0.0000e+00     \n",
      "Epoch 165/200\n",
      "491/491 [==============================] - 1s - loss: 0.0028 - acc: 0.0000e+00     \n",
      "Epoch 166/200\n",
      "491/491 [==============================] - 1s - loss: 0.0038 - acc: 0.0000e+00     \n",
      "Epoch 167/200\n",
      "491/491 [==============================] - 1s - loss: 0.0026 - acc: 0.0000e+00     \n",
      "Epoch 168/200\n",
      "491/491 [==============================] - 1s - loss: 0.0029 - acc: 0.0000e+00     \n",
      "Epoch 169/200\n",
      "491/491 [==============================] - 1s - loss: 0.0027 - acc: 0.0000e+00     \n",
      "Epoch 170/200\n",
      "491/491 [==============================] - 1s - loss: 0.0046 - acc: 0.0000e+00     \n",
      "Epoch 171/200\n",
      "491/491 [==============================] - 1s - loss: 0.0037 - acc: 0.0000e+00     \n",
      "Epoch 172/200\n",
      "491/491 [==============================] - 1s - loss: 0.0029 - acc: 0.0000e+00     \n",
      "Epoch 173/200\n",
      "491/491 [==============================] - 1s - loss: 0.0032 - acc: 0.0000e+00     \n",
      "Epoch 174/200\n",
      "491/491 [==============================] - 1s - loss: 0.0027 - acc: 0.0000e+00     \n",
      "Epoch 175/200\n",
      "491/491 [==============================] - 1s - loss: 0.0024 - acc: 0.0000e+00     \n",
      "Epoch 176/200\n",
      "491/491 [==============================] - 1s - loss: 0.0057 - acc: 0.0000e+00     \n",
      "Epoch 177/200\n",
      "491/491 [==============================] - 1s - loss: 0.0033 - acc: 0.0000e+00     \n",
      "Epoch 178/200\n",
      "491/491 [==============================] - 1s - loss: 0.0037 - acc: 0.0000e+00     \n",
      "Epoch 179/200\n",
      "491/491 [==============================] - 1s - loss: 0.0038 - acc: 0.0000e+00     \n",
      "Epoch 180/200\n",
      "491/491 [==============================] - 1s - loss: 0.0030 - acc: 0.0000e+00     \n",
      "Epoch 181/200\n",
      "491/491 [==============================] - 1s - loss: 0.0052 - acc: 0.0000e+00     \n",
      "Epoch 182/200\n",
      "491/491 [==============================] - 1s - loss: 0.0033 - acc: 0.0000e+00     \n",
      "Epoch 183/200\n",
      "491/491 [==============================] - 1s - loss: 0.0088 - acc: 0.0000e+00     \n",
      "Epoch 184/200\n",
      "491/491 [==============================] - 1s - loss: 0.0040 - acc: 0.0000e+00     \n",
      "Epoch 185/200\n",
      "491/491 [==============================] - 1s - loss: 0.0025 - acc: 0.0000e+00     \n",
      "Epoch 186/200\n",
      "491/491 [==============================] - 1s - loss: 0.0071 - acc: 0.0000e+00     \n",
      "Epoch 187/200\n",
      "491/491 [==============================] - 1s - loss: 0.0027 - acc: 0.0000e+00     \n",
      "Epoch 188/200\n",
      "491/491 [==============================] - 1s - loss: 0.0030 - acc: 0.0000e+00     \n",
      "Epoch 189/200\n",
      "491/491 [==============================] - 1s - loss: 0.0037 - acc: 0.0000e+00     \n",
      "Epoch 190/200\n",
      "491/491 [==============================] - 1s - loss: 0.0038 - acc: 0.0000e+00     \n",
      "Epoch 191/200\n",
      "491/491 [==============================] - 1s - loss: 0.0050 - acc: 0.0000e+00     \n",
      "Epoch 192/200\n",
      "491/491 [==============================] - 1s - loss: 0.0084 - acc: 0.0000e+00     \n",
      "Epoch 193/200\n",
      "491/491 [==============================] - 1s - loss: 0.0036 - acc: 0.0000e+00     \n",
      "Epoch 194/200\n",
      "491/491 [==============================] - 1s - loss: 0.0028 - acc: 0.0000e+00     \n",
      "Epoch 195/200\n",
      "491/491 [==============================] - 1s - loss: 0.0028 - acc: 0.0000e+00     \n",
      "Epoch 196/200\n",
      "491/491 [==============================] - 1s - loss: 0.0042 - acc: 0.0000e+00     \n",
      "Epoch 197/200\n",
      "491/491 [==============================] - 1s - loss: 0.0030 - acc: 0.0000e+00     \n",
      "Epoch 198/200\n",
      "491/491 [==============================] - 1s - loss: 0.0030 - acc: 0.0000e+00     \n",
      "Epoch 199/200\n",
      "491/491 [==============================] - 1s - loss: 0.0026 - acc: 0.0000e+00     \n",
      "Epoch 200/200\n",
      "491/491 [==============================] - 1s - loss: 0.0040 - acc: 0.0000e+00     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a434dad978>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=256,\n",
    "    nb_epoch=200,\n",
    "#     validation_split=0.2,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00 MSE (0.06 RMSE)\n",
      "acc: 0.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "print(\"%s: %.2f%%\\n\" % (model.metrics_names[1], trainScore[1]*100))\n",
    "\n",
    "# testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "# print(\"%s: %.2f%%\" % (model.metrics_names[1], testScore[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.997    0.99868  0.99219]\n",
      "  [ 0.989    0.99511  0.99384]\n",
      "  [ 0.9941   1.00619  0.99831]\n",
      "  [ 0.9707   0.97673  0.96903]\n",
      "  [ 0.97278  0.97395  0.96531]\n",
      "  [ 0.96918  0.96952  0.95251]\n",
      "  [ 0.94799  0.96179  0.95833]\n",
      "  [ 0.96     0.96119  0.9455 ]\n",
      "  [ 0.94781  0.95449  0.94656]\n",
      "  [ 0.94837  0.9491   0.94764]]]\n",
      "1/1 [==============================] - 0s\n",
      "[[ 0.88795871]]\n"
     ]
    }
   ],
   "source": [
    "my_test = np.array([np.array(df[0:window][::-1])])\n",
    "print(my_test)\n",
    "print(model.predict(my_test, batch_size=1, verbose=1))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
